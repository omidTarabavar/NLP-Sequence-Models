{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39429c4d",
   "metadata": {
    "colab_type": "text",
    "id": "C7oVbe_pLr3C"
   },
   "source": [
    "# Assignment 2 - Named Entity Recognition (NER)\n",
    "\n",
    "Welcome to the second programming assignment of Course 3. In this assignment, you will learn to build more complicated models with Tensorflow. By completing this assignment, you will be able to: \n",
    "\n",
    "- Design the architecture of a neural network, train it, and test it. \n",
    "- Process features and represents them\n",
    "- Understand word padding\n",
    "- Implement LSTMs\n",
    "- Test with your own sentence\n",
    "\n",
    "Before getting started take some time to read the following tips:\n",
    "\n",
    "#### TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:\n",
    "\n",
    "- All cells are frozen except for the ones where you need to submit your solutions.\n",
    "\n",
    "- You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "- You can add the comment # grade-up-to-here in any graded cell to signal the grader that it must only evaluate up to that point. This is helpful if you want to check if you are on the right track even if you are not done with the whole assignment. Be sure to remember to delete the comment afterwards!\n",
    "\n",
    "- To submit your notebook, save it and then click on the blue submit button at the beginning of the page.\n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Introduction](#1)\n",
    "- [ 2 - Exploring the Data](#2)\n",
    "  - [ 2.1 - Importing the Data](#2.1)\n",
    "- [ 3 -  Encoding](#3)\n",
    "  - [ 3.1 Enconding the sentences](#3.1)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 3.2 Encoding the labels](#3.2)\n",
    "  - [ 3.3 Padding the labels](#3.3)\n",
    "  - [ 3.4 Building the label vectorizer](#3.4)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 3.5 - Considerations about RNNs and LSTMs inputs](#3.5)\n",
    "- [ 4 - Building the Model](#4)\n",
    "  - [ 4.1 Model structure](#4.1)\n",
    "    - [ Exercise 3](#ex03)\n",
    "  - [ 4.2 Masked loss and metrics](#4.2)\n",
    "    - [ Exercise 4](#ex04)\n",
    "    - [ Exercise 5](#ex05)\n",
    "  - [ 4.3 A note on padding](#4.3)\n",
    "  - [ 4.4 - Training the Model](#4.4)\n",
    "- [ 5 - Compute Accuracy](#5)\n",
    "- [ 6 - Testing with your Own Sentence](#6)\n",
    "  - [ Exercise 6](#ex06)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63264b37",
   "metadata": {
    "colab_type": "text",
    "id": "ftT-5-yynCtl"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Introduction\n",
    "\n",
    "Let's begin by defining what a named entity recognition (NER) is. NER is a subtask of information extraction that locates and classifies named entities in a text. The named entities could be organizations, persons, locations, times, etc. \n",
    "\n",
    "For example:\n",
    "\n",
    "<img src = 'images/ner.png' width=\"width\" height=\"height\" style=\"width:600px;height:150px;\"/>\n",
    "\n",
    "Is labeled as follows: \n",
    "\n",
    "- French: geopolitical entity\n",
    "- Morocco: geographic entity \n",
    "- Christmas: time indicator\n",
    "\n",
    "Everything else that is labeled with an `O` is not considered to be a named entity. In this assignment, you will train a named entity recognition system that could be trained in a few seconds (on a GPU) and will get around 75% accuracy. You will then evaluate your model and see you get 97% accuracy! Finally, you will be able to test your named entity recognition system with your own sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22352fbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "JEY_jlQQR9SP",
    "outputId": "825f37fd-cf03-483a-a6b1-3d70da6f70f1",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# set random seeds to make this notebook easier to replicate\n",
    "tf.keras.utils.set_random_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd35d312",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import w2_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35b428",
   "metadata": {
    "colab_type": "text",
    "id": "_PpjG5MuLr3F"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Exploring the Data\n",
    "\n",
    "You will be using a dataset from Kaggle, which it will be preprocessed for you. The original data consists of four columns: the sentence number, the word, the part of speech of the word (it won't be used in this assignment), and the tags.  A few tags you might expect to see are: \n",
    "\n",
    "* geo: geographical entity\n",
    "* org: organization\n",
    "* per: person \n",
    "* gpe: geopolitical entity\n",
    "* tim: time indicator\n",
    "* art: artifact\n",
    "* eve: event\n",
    "* nat: natural phenomenon\n",
    "* O: filler word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75914c00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "-Jur1JnXnCtr",
    "outputId": "88584ab6-0a15-489b-db5b-eb474e129c4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "\n",
      "SENTENCE LABEL: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "\n",
      "ORIGINAL DATA:\n",
      "     Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "# display original kaggle data\n",
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding = \"ISO-8859-1\") \n",
    "train_sents = open('data/small/train/sentences.txt', 'r').readline()\n",
    "train_labels = open('data/small/train/labels.txt', 'r').readline()\n",
    "print('SENTENCE:', train_sents)\n",
    "print('SENTENCE LABEL:', train_labels)\n",
    "print('ORIGINAL DATA:\\n', data.head())\n",
    "del(data, train_sents, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8f676",
   "metadata": {
    "colab_type": "text",
    "id": "xoH6yBWVfzTb"
   },
   "source": [
    "<a name=\"2.1\"></a>\n",
    "### 2.1 - Importing the Data\n",
    "\n",
    "In this part, you will import the preprocessed data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323ddf01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        data = np.array([line.strip() for line in file.readlines()])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4dc9e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences = load_data('data/large/train/sentences.txt')\n",
    "train_labels = load_data('data/large/train/labels.txt')\n",
    "\n",
    "val_sentences = load_data('data/large/val/sentences.txt')\n",
    "val_labels = load_data('data/large/val/labels.txt')\n",
    "\n",
    "test_sentences = load_data('data/large/test/sentences.txt')\n",
    "test_labels = load_data('data/large/test/labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d817d",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 -  Encoding\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 Encoding the sentences\n",
    "\n",
    "In this section, you will use [`tf.keras.layers.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) to transform the sentences into integers, so they can be fed into the model you will build later on. \n",
    "\n",
    "You can use `help(tf.keras.layers.TextVectorization)` to further investigate the object and its parameters. \n",
    "\n",
    "The parameter you will need to pass explicitly is `standardize`. This will tell how the parser splits the sentences. By default, `standardize = 'lower_and_strip_punctuation'`, this means the parser will remove all punctuation and make everything lowercase. Note that this may influence the NER task, since an upper case in the middle of a sentence may indicate an entity. Furthermore, the sentences in the dataset are already split into tokens, and all tokens, including punctuation, are separated by a whitespace. The punctuations are also labeled. That said, you will use `standardize = None` so everything will just be split into single tokens and then mapped to a positive integer.\n",
    "\n",
    "Note that `tf.keras.layers.TextVectorization` will also pad the sentences. In this case, it will always pad using the largest sentence in the set you call it with. You will be calling it for the entire training/validation/test set, but padding won't impact at all the model's output, as you will see later on.\n",
    "\n",
    "After instantiating the object, you will need to adapt it to the **sentences training set**, so it will map every token in the training set to an integer. Also, it will by default create two tokens: one for unknown tokens and another for the padding token. Tensorflow maps in the following way:\n",
    "\n",
    "1. padding token: \"\", integer mapped: 0\n",
    "1. unknown token \"[UNK]\", integer mapped: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a73379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextVectorization in module keras.layers.preprocessing.text_vectorization:\n",
      "\n",
      "class TextVectorization(keras.engine.base_preprocessing_layer.PreprocessingLayer)\n",
      " |  TextVectorization(max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)\n",
      " |  \n",
      " |  A preprocessing layer which maps text features to integer sequences.\n",
      " |  \n",
      " |  This layer has basic options for managing text in a Keras model. It\n",
      " |  transforms a batch of strings (one example = one string) into either a list\n",
      " |  of token indices (one example = 1D tensor of integer token indices) or a\n",
      " |  dense representation (one example = 1D tensor of float values representing\n",
      " |  data about the example's tokens). This layer is meant to handle natural\n",
      " |  language inputs. To handle simple string inputs (categorical strings or\n",
      " |  pre-tokenized strings) see `tf.keras.layers.StringLookup`.\n",
      " |  \n",
      " |  The vocabulary for the layer must be either supplied on construction or\n",
      " |  learned via `adapt()`. When this layer is adapted, it will analyze the\n",
      " |  dataset, determine the frequency of individual string values, and create a\n",
      " |  vocabulary from them. This vocabulary can have unlimited size or be capped,\n",
      " |  depending on the configuration options for this layer; if there are more\n",
      " |  unique values in the input than the maximum vocabulary size, the most\n",
      " |  frequent terms will be used to create the vocabulary.\n",
      " |  \n",
      " |  The processing of each example contains the following steps:\n",
      " |  \n",
      " |  1. Standardize each example (usually lowercasing + punctuation stripping)\n",
      " |  2. Split each example into substrings (usually words)\n",
      " |  3. Recombine substrings into tokens (usually ngrams)\n",
      " |  4. Index tokens (associate a unique int value with each token)\n",
      " |  5. Transform each example using this index, either into a vector of ints or\n",
      " |     a dense float vector.\n",
      " |  \n",
      " |  Some notes on passing callables to customize splitting and normalization for\n",
      " |  this layer:\n",
      " |  \n",
      " |  1. Any callable can be passed to this Layer, but if you want to serialize\n",
      " |     this object you should only pass functions that are registered Keras\n",
      " |     serializables (see `tf.keras.utils.register_keras_serializable` for more\n",
      " |     details).\n",
      " |  2. When using a custom callable for `standardize`, the data received\n",
      " |     by the callable will be exactly as passed to this layer. The callable\n",
      " |     should return a tensor of the same shape as the input.\n",
      " |  3. When using a custom callable for `split`, the data received by the\n",
      " |     callable will have the 1st dimension squeezed out - instead of\n",
      " |     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
      " |     see `[\"string to split\", \"another string to split\"]`. The callable should\n",
      " |     return a Tensor with the first dimension containing the split tokens -\n",
      " |     in this example, we should see something like `[[\"string\", \"to\",\n",
      " |     \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n",
      " |     site natively compatible with `tf.strings.split()`.\n",
      " |  \n",
      " |  For an overview and full list of preprocessing layers, see the preprocessing\n",
      " |  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
      " |  \n",
      " |  Args:\n",
      " |    max_tokens: Maximum size of the vocabulary for this layer. This should\n",
      " |      only be specified when adapting a vocabulary or when setting\n",
      " |      `pad_to_max_tokens=True`. Note that this vocabulary\n",
      " |      contains 1 OOV token, so the effective number of tokens is\n",
      " |      `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\n",
      " |    standardize: Optional specification for standardization to apply to the\n",
      " |      input text. Values can be:\n",
      " |        - `None`: No standardization.\n",
      " |        - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\n",
      " |          punctuation removed.\n",
      " |        - `\"lower\"`: Text will be lowercased.\n",
      " |        - `\"strip_punctuation\"`: All punctuation will be removed.\n",
      " |        - Callable: Inputs will passed to the callable function, which should\n",
      " |          standardized and returned.\n",
      " |    split: Optional specification for splitting the input text. Values can be:\n",
      " |        - `None`: No splitting.\n",
      " |        - `\"whitespace\"`: Split on whitespace.\n",
      " |        - `\"character\"`: Split on each unicode character.\n",
      " |        - Callable: Standardized inputs will passed to the callable function,\n",
      " |          which should split and returned.\n",
      " |    ngrams: Optional specification for ngrams to create from the\n",
      " |      possibly-split input text. Values can be None, an integer or tuple of\n",
      " |      integers; passing an integer will create ngrams up to that integer, and\n",
      " |      passing a tuple of integers will create ngrams for the specified values\n",
      " |      in the tuple. Passing None means that no ngrams will be created.\n",
      " |    output_mode: Optional specification for the output of the layer. Values\n",
      " |      can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the\n",
      " |      layer as follows:\n",
      " |        - `\"int\"`: Outputs integer indices, one integer index per split string\n",
      " |          token. When `output_mode == \"int\"`, 0 is reserved for masked\n",
      " |          locations; this reduces the vocab size to\n",
      " |          `max_tokens - 2` instead of `max_tokens - 1`.\n",
      " |        - `\"multi_hot\"`: Outputs a single int array per batch, of either\n",
      " |          vocab_size or max_tokens size, containing 1s in all elements where\n",
      " |          the token mapped to that index exists at least once in the batch\n",
      " |          item.\n",
      " |        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n",
      " |          the number of times the token at that index appeared in the\n",
      " |          batch item.\n",
      " |        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied\n",
      " |          to find the value in each token slot.\n",
      " |      For `\"int\"` output, any shape of input and output is supported. For all\n",
      " |      other output modes, currently only rank 1 inputs (and rank 2 outputs\n",
      " |      after splitting) are supported.\n",
      " |    output_sequence_length: Only valid in INT mode. If set, the output will\n",
      " |      have its time dimension padded or truncated to exactly\n",
      " |      `output_sequence_length` values, resulting in a tensor of shape\n",
      " |      `(batch_size, output_sequence_length)` regardless of how many tokens\n",
      " |      resulted from the splitting step. Defaults to None.\n",
      " |    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n",
      " |      modes. If True, the output will have its feature axis padded to\n",
      " |      `max_tokens` even if the number of unique tokens in the vocabulary is\n",
      " |      less than max_tokens, resulting in a tensor of shape `(batch_size,\n",
      " |      max_tokens)` regardless of vocabulary size. Defaults to False.\n",
      " |    vocabulary: Optional. Either an array of strings or a string path to a\n",
      " |      text file. If passing an array, can pass a tuple, list, 1D numpy array,\n",
      " |      or 1D tensor containing the string vocbulary terms. If passing a file\n",
      " |      path, the file should contain one line per term in the vocabulary. If\n",
      " |      this argument is set, there is no need to `adapt()` the layer.\n",
      " |    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\n",
      " |      1D numpy array, or 1D tensor or the same length as the vocabulary,\n",
      " |      containing the floating point inverse document frequency weights, which\n",
      " |      will be multiplied by per sample term counts for the final `tf_idf`\n",
      " |      weight. If the `vocabulary` argument is set, and `output_mode` is\n",
      " |      `\"tf_idf\"`, this argument must be supplied.\n",
      " |    ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns\n",
      " |      a `RaggedTensor` instead of a dense `Tensor`, where each sequence may\n",
      " |      have a different length after string splitting. Defaults to False.\n",
      " |    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n",
      " |      `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n",
      " |      dense `Tensor`. Defaults to False.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  This example instantiates a `TextVectorization` layer that lowercases text,\n",
      " |  splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
      " |  \n",
      " |  >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
      " |  >>> max_features = 5000  # Maximum vocab size.\n",
      " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
      " |  >>>\n",
      " |  >>> # Create the layer.\n",
      " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
      " |  ...  max_tokens=max_features,\n",
      " |  ...  output_mode='int',\n",
      " |  ...  output_sequence_length=max_len)\n",
      " |  >>>\n",
      " |  >>> # Now that the vocab layer has been created, call `adapt` on the\n",
      " |  >>> # text-only dataset to create the vocabulary. You don't have to batch,\n",
      " |  >>> # but for large datasets this means we're not keeping spare copies of\n",
      " |  >>> # the dataset.\n",
      " |  >>> vectorize_layer.adapt(text_dataset.batch(64))\n",
      " |  >>>\n",
      " |  >>> # Create the model that uses the vectorize text layer\n",
      " |  >>> model = tf.keras.models.Sequential()\n",
      " |  >>>\n",
      " |  >>> # Start by creating an explicit input layer. It needs to have a shape of\n",
      " |  >>> # (1,) (because we need to guarantee that there is exactly one string\n",
      " |  >>> # input per batch), and the dtype needs to be 'string'.\n",
      " |  >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
      " |  >>>\n",
      " |  >>> # The first layer in our model is the vectorization layer. After this\n",
      " |  >>> # layer, we have a tensor of shape (batch_size, max_len) containing\n",
      " |  >>> # vocab indices.\n",
      " |  >>> model.add(vectorize_layer)\n",
      " |  >>>\n",
      " |  >>> # Now, the model can map strings to integers, and you can add an\n",
      " |  >>> # embedding layer to map these integers to learned embeddings.\n",
      " |  >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
      " |  >>> model.predict(input_data)\n",
      " |  array([[2, 1, 4, 0],\n",
      " |         [1, 3, 0, 0]])\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  This example instantiates a `TextVectorization` layer by passing a list\n",
      " |  of vocabulary terms to the layer's `__init__()` method.\n",
      " |  \n",
      " |  >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
      " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
      " |  >>>\n",
      " |  >>> # Create the layer, passing the vocab directly. You can also pass the\n",
      " |  >>> # vocabulary arg a path to a file containing one vocabulary word per\n",
      " |  >>> # line.\n",
      " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
      " |  ...  max_tokens=max_features,\n",
      " |  ...  output_mode='int',\n",
      " |  ...  output_sequence_length=max_len,\n",
      " |  ...  vocabulary=vocab_data)\n",
      " |  >>>\n",
      " |  >>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
      " |  >>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
      " |  >>> # padding token ('') and OOV token ('[UNK]') as well as the passed\n",
      " |  >>> # tokens.\n",
      " |  >>> vectorize_layer.get_vocabulary()\n",
      " |  ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextVectorization\n",
      " |      keras.engine.base_preprocessing_layer.PreprocessingLayer\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)\n",
      " |  \n",
      " |  adapt(self, data, batch_size=None, steps=None)\n",
      " |      Computes a vocabulary of string terms from tokens in a dataset.\n",
      " |      \n",
      " |      Calling `adapt()` on a `TextVectorization` layer is an alternative to\n",
      " |      passing in a precomputed vocabulary on construction via the `vocabulary`\n",
      " |      argument. A `TextVectorization` layer should always be either adapted\n",
      " |      over a dataset or supplied with a vocabulary.\n",
      " |      \n",
      " |      During `adapt()`, the layer will build a vocabulary of all string tokens\n",
      " |      seen in the dataset, sorted by occurrence count, with ties broken by\n",
      " |      sort order of the tokens (high to low). At the end of `adapt()`, if\n",
      " |      `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n",
      " |      size. For example, adapting a layer with `max_tokens=1000` will compute\n",
      " |      the 1000 most frequent tokens occurring in the input dataset. If\n",
      " |      `output_mode='tf-idf'`, `adapt()` will also learn the document\n",
      " |      frequencies of each token in the input dataset.\n",
      " |      \n",
      " |      In order to make `TextVectorization` efficient in any distribution\n",
      " |      context, the vocabulary is kept static with respect to any compiled\n",
      " |      `tf.Graph`s that call the layer. As a consequence, if the layer is\n",
      " |      adapted a second time, any models using the layer should be re-compiled.\n",
      " |      For more information see\n",
      " |      `tf.keras.layers.experimental.preprocessing.PreprocessingLayer.adapt`.\n",
      " |      \n",
      " |      `adapt()` is meant only as a single machine utility to compute layer\n",
      " |      state.  To analyze a dataset that cannot fit on a single machine, see\n",
      " |      [Tensorflow Transform](\n",
      " |      https://www.tensorflow.org/tfx/transform/get_started) for a\n",
      " |      multi-machine, map-reduce solution.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: The data to train on. It can be passed either as a\n",
      " |            `tf.data.Dataset`, or as a numpy array.\n",
      " |        batch_size: Integer or `None`.\n",
      " |            Number of samples per state update.\n",
      " |            If unspecified, `batch_size` will default to 32.\n",
      " |            Do not specify the `batch_size` if your data is in the\n",
      " |            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |            (since they generate batches).\n",
      " |        steps: Integer or `None`.\n",
      " |            Total number of steps (batches of samples)\n",
      " |            When training with input tensors such as\n",
      " |            TensorFlow data tensors, the default `None` is equal to\n",
      " |            the number of samples in your dataset divided by\n",
      " |            the batch size, or 1 if that cannot be determined. If x is a\n",
      " |            `tf.data` dataset, and 'steps' is None, the epoch will run until\n",
      " |            the input dataset is exhausted. When passing an infinitely\n",
      " |            repeating dataset, you must specify the `steps` argument. This\n",
      " |            argument is not supported with array inputs.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      The `call()` method may not create state (except in its first\n",
      " |      invocation, wrapping the creation of variables or other resources in\n",
      " |      `tf.init_scope()`).  It is recommended to create state in `__init__()`,\n",
      " |      or the `build()` method that is called automatically before `call()`\n",
      " |      executes the first time.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as\n",
      " |            tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs`\n",
      " |            only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask\n",
      " |            generated for `inputs` by the previous layer (if `input` did come\n",
      " |            from a layer that generated a corresponding mask, i.e. if it came\n",
      " |            from a Keras layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  compute_output_signature(self, input_spec)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalize the statistics for the preprocessing layer.\n",
      " |      \n",
      " |      This method is called at the end of `adapt` or after restoring a\n",
      " |      serialized preprocessing layer's state. This method handles any one-time\n",
      " |      operations that should occur on the layer's state before\n",
      " |      `Layer.__call__`.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_vocabulary(self, include_special_tokens=True)\n",
      " |      Returns the current vocabulary of the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        include_special_tokens: If True, the returned vocabulary will include\n",
      " |          the padding and OOV tokens, and a term's index in the vocabulary\n",
      " |          will equal the term's index when calling the layer. If False, the\n",
      " |          returned vocabulary will not include any padding or OOV tokens.\n",
      " |  \n",
      " |  reset_state(self)\n",
      " |      Resets the statistics of the preprocessing layer.\n",
      " |  \n",
      " |  set_vocabulary(self, vocabulary, idf_weights=None)\n",
      " |      Sets vocabulary (and optionally document frequency) data for this layer.\n",
      " |      \n",
      " |      This method sets the vocabulary and idf weights for this layer directly,\n",
      " |      instead of analyzing a dataset through 'adapt'. It should be used\n",
      " |      whenever the vocab (and optionally document frequency) information is\n",
      " |      already known.  If vocabulary data is already present in the layer, this\n",
      " |      method will replace it.\n",
      " |      \n",
      " |      Args:\n",
      " |        vocabulary: Either an array or a string path to a text file. If\n",
      " |          passing an array, can pass a tuple, list, 1D numpy array, or 1D\n",
      " |          tensor containing the vocbulary terms. If passing a file path, the\n",
      " |          file should contain one line per term in the vocabulary.\n",
      " |        idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\n",
      " |          document frequency weights with equal length to vocabulary. Must be\n",
      " |          set if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If there are too many inputs, the inputs do not match, or\n",
      " |          input data is missing.\n",
      " |        RuntimeError: If the vocabulary cannot be set when this function is\n",
      " |          called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\"\n",
      " |          modes, if `pad_to_max_tokens` is False and the layer itself has\n",
      " |          already been called.\n",
      " |  \n",
      " |  update_state(self, data)\n",
      " |      Accumulates statistics for the preprocessing layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A mini-batch of inputs to the layer.\n",
      " |  \n",
      " |  vocabulary_size(self)\n",
      " |      Gets the current size of the layer's vocabulary.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The integer size of the vocabulary, including optional mask and\n",
      " |        OOV indices.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  compile(self, run_eagerly=None, steps_per_execution=None)\n",
      " |      Configures the layer for `adapt`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |          logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |          this as `None` unless your `Model` cannot be run inside a\n",
      " |          `tf.function`.\n",
      " |        steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
      " |          during each `tf.function` call. Running multiple batches inside a\n",
      " |          single `tf.function` call can greatly improve performance on TPUs or\n",
      " |          small models with a large Python overhead.\n",
      " |  \n",
      " |  make_adapt_function(self)\n",
      " |      Creates a function to execute one step of `adapt`.\n",
      " |      \n",
      " |      This method can be overridden to support custom adapt logic.\n",
      " |      This method is called by `PreprocessingLayer.adapt`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` settings,\n",
      " |      and delegates the actual state update logic to\n",
      " |      `PreprocessingLayer.update_state`.\n",
      " |      \n",
      " |      This function is cached the first time `PreprocessingLayer.adapt`\n",
      " |      is called. The cache is cleared whenever `PreprocessingLayer.compile`\n",
      " |      is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, retrieve a batch, and update the state of the\n",
      " |        layer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
      " |  \n",
      " |  is_adapted\n",
      " |      Whether the layer has been fit to data already.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific\n",
      " |          uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid\n",
      " |          value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the\n",
      " |          constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |          for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from abc.ABCMeta\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from abc.ABCMeta\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.layers.TextVectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbd7d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"ex01\"></a>\n",
    "### Exercise 1\n",
    "\n",
    "**Instructions**: Use the object tf.keras.layers.TextVectorization and the appropriate parameters to build a function that inputs an array of sentences and outputs an adapted sentence vectorizer and its vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ec60b8",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: get_sentence_vectorizer\n",
    "def get_sentence_vectorizer(sentences):\n",
    "    tf.keras.utils.set_random_seed(33) ## Do not change this line. \n",
    "    \"\"\"\n",
    "    Create a TextVectorization layer for sentence tokenization and adapt it to the provided sentences.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list of str): Sentences for vocabulary adaptation.\n",
    "\n",
    "    Returns:\n",
    "    sentence_vectorizer (tf.keras.layers.TextVectorization): TextVectorization layer for sentence tokenization.\n",
    "    vocab (list of str): Extracted vocabulary.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    sentence_vectorizer = tf.keras.layers.TextVectorization(standardize=None)\n",
    "    sentence_vectorizer.adapt(sentences)\n",
    "    vocab = sentence_vectorizer.get_vocabulary()\n",
    "    \n",
    "\n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    return sentence_vectorizer, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ec699",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vocab size: 4650\n",
      "Sentence: I like learning new NLP models !\n",
      "Sentence vectorized: [ 296  314    1   59    1    1 4649]\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer, test_vocab = get_sentence_vectorizer(train_sentences[:1000])\n",
    "print(f\"Test vocab size: {len(test_vocab)}\")\n",
    "\n",
    "sentence = \"I like learning new NLP models !\"\n",
    "sentence_vectorized = test_vectorizer(sentence)\n",
    "print(f\"Sentence: {sentence}\\nSentence vectorized: {sentence_vectorized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec665454",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Test vocab size: 4650\n",
    "Sentence: I like learning new NLP models !\n",
    "Sentence vectorized: [ 296  314    1   59    1    1 4649]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7bb13d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_get_sentence_vectorizer(get_sentence_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c869d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 36 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x0000027BE9D00D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "sentence_vectorizer, vocab = get_sentence_vectorizer(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49512450",
   "metadata": {},
   "source": [
    "<a name=\"3.2\"></a>\n",
    "### 3.2 Encoding the labels\n",
    "\n",
    "In this section you will encode the labels. The process is a bit simpler than encoding the sentences, because there are only a few tags, compared with words in the vocabulary. Note, also, that there will be one extra tag to represent the padded token that some sentences may have included. Padding will not interfere at all in this task, as you will see further on. Run the next cell to print one example of a tag related to one sentence.\n",
    "\n",
    "Because there is no meaning in having an UNK token for labels and the padding token will be another number different from 0 (you will see why soon), TextVectorization is not a good choice.\n",
    "\n",
    "You will need also to pad the labels, because the number of labels must match the number of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "727b049f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "Labels: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence: {train_sentences[0]}\")\n",
    "print(f\"Labels: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd4225",
   "metadata": {},
   "source": [
    "You will build the next function to extract all the different tags in a given set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6123a983",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tags(labels):\n",
    "    tag_set = set() # Define an empty set\n",
    "    for el in labels:\n",
    "        for tag in el.split(\" \"):\n",
    "            tag_set.add(tag)\n",
    "    tag_list = list(tag_set) \n",
    "    tag_list.sort()\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cb3d4be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = get_tags(train_labels)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b1eea",
   "metadata": {},
   "source": [
    "Now you will need to generate a **tag map**, i.e., a mapping between the tags and **positive** integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88043496",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_tag_map(tags):\n",
    "    tag_map = {}\n",
    "    for i,tag in enumerate(tags):\n",
    "        tag_map[tag] = i \n",
    "    return tag_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747233ee",
   "metadata": {},
   "source": [
    "The `tag_map` is a dictionary that maps the tags that you could have to numbers. Run the cell below to see the possible classes you will be predicting. The prepositions in the tags mean:\n",
    "* I: Token is inside an entity.\n",
    "* B: Token begins an entity.\n",
    "\n",
    "If you had the sentence \n",
    "\n",
    "**\"Sharon flew to Miami on Friday\"**\n",
    "\n",
    "The tags would look like:\n",
    "\n",
    "```\n",
    "Sharon B-per\n",
    "flew   O\n",
    "to     O\n",
    "Miami  B-geo\n",
    "on     O\n",
    "Friday B-tim\n",
    "```\n",
    "\n",
    "where you would have three tokens beginning with B-, since there are no multi-token entities in the sequence. But if you added Sharon's last name to the sentence:\n",
    "\n",
    "**\"Sharon Floyd flew to Miami on Friday\"**\n",
    "\n",
    "```\n",
    "Sharon B-per\n",
    "Floyd  I-per\n",
    "flew   O\n",
    "to     O\n",
    "Miami  B-geo\n",
    "on     O\n",
    "Friday B-tim\n",
    "```\n",
    "\n",
    "Your tags would change to show first \"Sharon\" as B-per, and \"Floyd\" as I-per, where I- indicates an inner token in a multi-token sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcfdscb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"
     ]
    }
   ],
   "source": [
    "tag_map = make_tag_map(tags)\n",
    "print(tag_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd640d3",
   "metadata": {},
   "source": [
    "<a name=\"3.3\"></a>\n",
    "### 3.3 Padding the labels\n",
    "\n",
    "In this section, you will pad the labels. TextVectorization already padded the sentences, so you must ensure that the labels are properly padded as well. This is not a hard task for two main reasons:\n",
    "\n",
    "1. Tensorflow has built-in functions for padding\n",
    "1. Padding will be performed uniformly per dataset (train, validation and test) using the maximum sentence length in each dataset and the size of each sentence is exactly the same as the size of their respective labels.\n",
    "\n",
    "You will pad the vectorized labels with the value -1. You will not use 0 to simplify loss masking and evaluation in further steps. This is because to properly classify one token, a log softmax transformation will be performed and the index with greater value will be the index label. Since index starts at 0, it is better to keep the label 0 as a valid index, even though it is possible to also use 0 as a mask value for labels, but it would require some tweaks in the model architecture or in the loss computation.\n",
    "\n",
    "Tensorflow provides the function [`tf.keras.utils.pad_sequences`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences). The arguments you will need are:\n",
    "\n",
    "- `sequences`: An array with the labels.\n",
    "- `padding`: The position where padding will take place, the standard is `pre`, meaning the sequences will be padded at the beginning. You need to pass the argument `post`.\n",
    "- `value`: Padding value. The default value is  0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c6804",
   "metadata": {},
   "source": [
    "<a name=\"3.4\"></a>\n",
    "### 3.4 Building the label vectorizer\n",
    "\n",
    "Now you're ready to code the label vectorizer.\n",
    "\n",
    "<a name=\"ex02\"></a>\n",
    "### Exercise 2\n",
    "\n",
    "**Instructions**: You will build the label vectorizer, a function that inputs a list of labels and a tag mapping and outputs their respective label ids via a tag map lookup. The tensorflow function `pad_sequences` can be called by `tf.keras.utils.pad_sequences`. You may also type `help(tf.keras.utils.pad_sequences)` to see its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c829deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_sequences in module keras.utils.data_utils:\n",
      "\n",
      "pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
      "    Pads sequences to the same length.\n",
      "    \n",
      "    This function transforms a list (of length `num_samples`)\n",
      "    of sequences (lists of integers)\n",
      "    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n",
      "    `num_timesteps` is either the `maxlen` argument if provided,\n",
      "    or the length of the longest sequence in the list.\n",
      "    \n",
      "    Sequences that are shorter than `num_timesteps`\n",
      "    are padded with `value` until they are `num_timesteps` long.\n",
      "    \n",
      "    Sequences longer than `num_timesteps` are truncated\n",
      "    so that they fit the desired length.\n",
      "    \n",
      "    The position where padding or truncation happens is determined by\n",
      "    the arguments `padding` and `truncating`, respectively.\n",
      "    Pre-padding or removing values from the beginning of the sequence is the\n",
      "    default.\n",
      "    \n",
      "    >>> sequence = [[1], [2, 3], [4, 5, 6]]\n",
      "    >>> tf.keras.preprocessing.sequence.pad_sequences(sequence)\n",
      "    array([[0, 0, 1],\n",
      "           [0, 2, 3],\n",
      "           [4, 5, 6]], dtype=int32)\n",
      "    \n",
      "    >>> tf.keras.preprocessing.sequence.pad_sequences(sequence, value=-1)\n",
      "    array([[-1, -1,  1],\n",
      "           [-1,  2,  3],\n",
      "           [ 4,  5,  6]], dtype=int32)\n",
      "    \n",
      "    >>> tf.keras.preprocessing.sequence.pad_sequences(sequence, padding='post')\n",
      "    array([[1, 0, 0],\n",
      "           [2, 3, 0],\n",
      "           [4, 5, 6]], dtype=int32)\n",
      "    \n",
      "    >>> tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=2)\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [5, 6]], dtype=int32)\n",
      "    \n",
      "    Args:\n",
      "        sequences: List of sequences (each sequence is a list of integers).\n",
      "        maxlen: Optional Int, maximum length of all sequences. If not provided,\n",
      "            sequences will be padded to the length of the longest individual\n",
      "            sequence.\n",
      "        dtype: (Optional, defaults to `\"int32\"`). Type of the output sequences.\n",
      "            To pad sequences with variable length strings, you can use `object`.\n",
      "        padding: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n",
      "            pad either before or after each sequence.\n",
      "        truncating: String, \"pre\" or \"post\" (optional, defaults to `\"pre\"`):\n",
      "            remove values from sequences larger than\n",
      "            `maxlen`, either at the beginning or at the end of the sequences.\n",
      "        value: Float or String, padding value. (Optional, defaults to 0.)\n",
      "    \n",
      "    Returns:\n",
      "        Numpy array with shape `(len(sequences), maxlen)`\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: In case of invalid values for `truncating` or `padding`,\n",
      "            or in case of invalid shape for a `sequences` entry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.utils.pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a0a6532",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: label_vectorizer\n",
    "def label_vectorizer(labels, tag_map):\n",
    "    \"\"\"\n",
    "    Convert list of label strings to padded label IDs using a tag mapping.\n",
    "\n",
    "    Parameters:\n",
    "    labels (list of str): List of label strings.\n",
    "    tag_map (dict): Dictionary mapping tags to IDs.\n",
    "    Returns:\n",
    "    label_ids (numpy.ndarray): Padded array of label IDs.\n",
    "    \"\"\"\n",
    "    label_ids = [] # It can't be a numpy array yet, since each sentence has a different size\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    for element in labels:\n",
    "        tokens = element.split()\n",
    "        token_ids = []\n",
    "        for token in tokens:\n",
    "            token_ids.append(tag_map[token])\n",
    "        label_ids.append(token_ids)\n",
    "\n",
    "    label_ids = tf.keras.utils.pad_sequences(label_ids, padding='post', value= -1)    \n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02l23421",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\n",
      "Labels: O O O O O B-gpe O O O O B-geo O O O O O O O B-gpe O O O O O\n",
      "Vectorized labels: [[16 16 16 16 16  3 16 16 16 16  2 16 16 16 16 16 16 16  3 16 16 16 16 16]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence: {train_sentences[5]}\")\n",
    "print(f\"Labels: {train_labels[5]}\")\n",
    "print(f\"Vectorized labels: {label_vectorizer([train_labels[5]], tag_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64508654",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Sentence: The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\n",
    "Labels: O O O O O B-gpe O O O O B-geo O O O O O O O B-gpe O O O O O\n",
    "Vectorized labels: [[16 16 16 16 16  3 16 16 16 16  2 16 16 16 16 16 16 16  3 16 16 16 16 16]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de64e07c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_label_vectorizer(label_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abf2c8",
   "metadata": {},
   "source": [
    "## 4 Building the Dataset\n",
    "\n",
    "In this section, you will build the dataset for training, validation and testing. You will be using [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) class, which provides an optimized way to handle data to feed into a tensorflow model. It may be not as straightforward as a pandas dataset, but it avoids keeping all the data in memory, thus it makes the training faster.\n",
    "\n",
    "You will be using the `tf.data.Dataset.from_tensor_slices` function that converts any iterable into a Tensorflow dataset. You can pass a tuple of `(sentences,labels)` and Tensorflow will understand that each sentence is mapped to its respective label, therefore it is expected that if a tuple of arrays is passed, both arrays have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303db421",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset(sentences, labels, sentence_vectorizer, tag_map):\n",
    "    sentences_ids = sentence_vectorizer(sentences)\n",
    "    labels_ids = label_vectorizer(labels, tag_map = tag_map)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sentences_ids, labels_ids))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb886f",
   "metadata": {},
   "source": [
    "The next cell will use the function defined above to generate a Tensorflow Dataset for each of the train, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc31ffcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = generate_dataset(train_sentences,train_labels, sentence_vectorizer, tag_map)\n",
    "val_dataset = generate_dataset(val_sentences,val_labels,  sentence_vectorizer, tag_map)\n",
    "test_dataset = generate_dataset(test_sentences, test_labels,  sentence_vectorizer, tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a0c9e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "xM9B_Rwxd01i",
    "outputId": "db098ed6-4351-41f7-cfdb-e45dd3798ebf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of outputs is 17\n",
      "Num of vocabulary words in the training set: 29847\n",
      "The training size is 33570\n",
      "The validation size is 7194\n",
      "An example of the first sentence is\n",
      "\t [1046    6 1121   18 1832  232  543    7  528    2  158    5   60    9\n",
      "  648    2  922    6  192   87   22   16   54    3    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "An example of its corresponding label is\n",
      "\t [16 16 16 16 16 16  2 16 16 16 16 16  2 16 16 16 16 16  3 16 16 16 16 16\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Exploring information about the training data\n",
    "print(f'The number of outputs is {len(tags)}')\n",
    "# The number of vocabulary tokens (including <PAD>)\n",
    "g_vocab_size = len(vocab)\n",
    "print(f\"Num of vocabulary words in the training set: {g_vocab_size}\")\n",
    "print('The training size is', len(train_dataset))\n",
    "print('The validation size is', len(val_dataset))\n",
    "print('An example of the first sentence is\\n\\t', next(iter(train_dataset))[0].numpy())\n",
    "print('An example of its corresponding label is\\n\\t', next(iter(train_dataset))[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ad50c",
   "metadata": {},
   "source": [
    "<a name=\"3.5\"></a>\n",
    "### 3.5 - Considerations about RNNs and LSTMs inputs\n",
    "\n",
    "Tensorflow implementation of RNNs (in particular LSTMs) allow you to pass a variable size of input sentences, however this cannot be done **in the same batch**. You must assure that, for each batch, the shapes for our input tensors are the same. \n",
    "\n",
    "A second point here is that, for this purpose, the size of the padding should not influence the final result. Therefore, it does not matter if you perform the padding for each batch or in the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e7dcc",
   "metadata": {
    "colab_type": "text",
    "id": "4SWxKhkVLr3P"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Building the Model\n",
    "\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1 Model structure\n",
    "\n",
    "You will now implement the model that will be able to determine the tags of sentences like the following:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "<img src = 'images/ner1.png' width=\"width\" height=\"height\" style=\"width:500px;height:150px;\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The model architecture will be as follows: \n",
    "\n",
    "<img src = 'images/ner2.png' width=\"width\" height=\"height\" style=\"width:600px;height:250px;\"/>\n",
    "\n",
    "\n",
    "Concretely, your inputs will be sentences represented as tensors that are fed to a model with:\n",
    "\n",
    "* An Embedding layer,\n",
    "* A LSTM layer\n",
    "* A Dense layer\n",
    "* A log softmax layer.\n",
    "\n",
    "You may choose between outputting only the very last LSTM output for each sentence, but you may also request the LSTM to output every value for a sentence - this is what you want. You will need every output, because the idea is to label every token in the sentence and not to predict the next token or even make an overall classification task for that sentence. \n",
    "\n",
    "This implies that when you input a single sentence, such as `[452, 3400, 123, 0, 0, 0]`, the expected output should be an array for each word ID, with a length equal to the number of tags. This output is obtained by applying the LogSoftfmax function for each of the `len(tags)` values. So, in the case of the example array with a shape of `(6,)`, the output should be an array with a shape of `(6, len(tags))`.\n",
    "\n",
    "In your case, you've seen that each sentence in the training set is 104 values long, so in a batch of, say, 64 tensors, the model shoud input a tensor of shape `(64,104)` and output another tensor with shape `(64,104,17)`. \n",
    "\n",
    "Good news! We won't make you implement the LSTM cell drawn above. You will be in charge of the overall architecture of the model. \n",
    "\n",
    "<a name=\"ex03\"></a>\n",
    "### Exercise 3\n",
    "\n",
    "**Instructions:** Implement the NER model, with the architecture discussed in the lectures. All the necessary layers are objects from the `tensorflow.keras.layers` library, but they are already loaded in memory, so you do not have to worry about function calls.\n",
    "\n",
    "Please utilize help function e.g. `help(tf.keras.layers.Dense)` for more information on a layer\n",
    "   \n",
    "- [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential): Combinator that applies layers serially (by function composition) - **this is not properly a layer (it is under `tensorflow.keras` only and not under `tensorflow.keras.layers`)**. It is in fact a Tensorflow [model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) object.\n",
    "    - You can add the layers to a `Sequential` layer by calling the method `.add(layer)`.  \n",
    "    - You may skip the input shape and pass it in the first layer you instantiate, if necessary (RNNs usually don't need to fix an input length).\n",
    "\n",
    "\n",
    "-  [tf.keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): Initializes the embedding layer. An embedding layer in tensorflow will input only **positive integers**.\n",
    "    - `Embedding(input_dim, output_dim, mask_zero = False)`.\n",
    "    - `input_dim` is the expected range of integers for each tensor in the batch. Note that the input_dim is not related to array size, but to the possible range of integers expected in the input. Usually this is the vocabulary size, but it may differ by 1, depending on further parameters.  See below. \n",
    "    - `output_dim` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example). Each word processed will be assigned an array of size `output_dim`. So if one array of shape (3,) is passed (example of such an array `[100,203,204]`), then the Embedding layer should have output shape (3,output_dim).\n",
    "    - `mask_zero` is a boolean telling whether 0 is a mask value or not. If `mask_zero = True`, then some considerations must be done: \n",
    "                1. The value 0 should be reserved as the mask value, as it will be ignored in training.\n",
    "                2. You need to add 1 in `input_dim`, since now Tensorflow will consider that one extra 0 value may show up in each sentence.\n",
    "\n",
    "-  [tf.keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): An LSTM layer. \n",
    "    - `LSTM(units, return_sequences)` Builds an LSTM layer with hidden state and cell sizes equal to `units`. The arguments you will need: \n",
    "            1. `units`: It is the number of `LSTM` cells you will create to pass every input to. In this case, set the `units` as the Embedding `output_dim`. This is just a choice, in fact there is no static rule preventing one from choosing any amount of LSTM units. \n",
    "            2. `return_sequences`: A boolean, telling whether you want to return every output value from the LSTM cells. If `return_sequences = False`, then the LSTM output shape will be `(batch_size, units)`. Otherwise, it is `(batch_size, sentence_length, units)`, since there will be an output for each word in the sentence.\n",
    "\n",
    "\n",
    "-  [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): A dense layer.\n",
    "    - `Dense(units, activation)`: The parameters for this layer are: \n",
    "            1. `units`: It is the number of units chosen for this dense layer, i.e., it is the dimensionality of the output space. In this case, each value passed through the Dense layer must be mapped into a vector with length `num_of_classes` (in this case, `len(tags)`). \n",
    "            2. `activation`: This is the activation that will be performed after computing the values in the Dense layer. Since the Dense layer comes before the LogSoftmax step, you can pass the LogSoftmax function as activation function here. **You can find the implementation for LogSoftmax under `tf.nn`. So you may call it as `tf.nn.log_softmax`. See its documentation [here](https://www.tensorflow.org/api_docs/python/tf/nn/log_softmax).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf7bc5",
   "metadata": {},
   "source": [
    "**Instructions**: You will build a function that inputs the number of tags, the vocabulary size and an optional parameter to control the embedding dimension and outputs a tensorflow model as discussed in the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2493e30",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: NER\n",
    "def NER(len_tags, vocab_size, embedding_dim = 50):\n",
    "    \"\"\"\n",
    "    Create a Named Entity Recognition (NER) model.\n",
    "\n",
    "    Parameters:\n",
    "    len_tags (int): Number of NER tags (output classes).\n",
    "    vocab_size (int): Vocabulary size.\n",
    "    embedding_dim (int, optional): Dimension of embedding and LSTM layers (default is 50).\n",
    "\n",
    "    Returns:\n",
    "    model (Sequential): NER model.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    model = tf.keras.Sequential(name= 'sequential')\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size+1,embedding_dim,mask_zero = True))\n",
    "    model.add(tf.keras.layers.LSTM(units=embedding_dim,return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dense(len_tags,activation = tf.nn.log_softmax))\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b35453f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_NER(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ab3d3",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2 Masked loss and metrics\n",
    "\n",
    "Before training the model, you need to create your own function to compute the accuracy. Tensorflow has built-in accuracy metrics but you cannot pass values to be ignored. This will impact the calculations, since you must remove the padded values. Before diving into the exercise, let's just make some points clear.\n",
    "\n",
    "Usually, the metric that inputs true labels and predicted labels and outputs how many times the predicted and true labels match is called `accuracy`. In some cases, however, there is one more step before getting the predicted labels. This may happen if, instead of passing the predicted labels, a vector of probabilities is passed. In such case, there is a need to perform an `argmax` for each prediction to find the appropriate predicted label. Such situations happen very often, therefore Tensorflow has a set of functions, with prefix `Sparse`, that performs this operation in the backend. Unfortunately, it does not provide values to ignore in the accuracy case. This is what you will work on now. \n",
    "\n",
    "Note that the model's prediction has 3 axes: \n",
    "- the number of examples (batch size)\n",
    "- the number of words in each example (padded to be as long as the longest sentence in the batch)\n",
    "- the number of possible targets (the 17 named entity tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02eca7a",
   "metadata": {},
   "source": [
    "Another important function is the loss function. In this case, you will use the Cross Entropy loss, but you need a multiclass implementation of it, also you may look for its `Sparse` version. Tensorflow has a SparseCategoricalCrossentropy loss function, which it is already imported by the name SparseCategoricalCrossEntropy.\n",
    "\n",
    "[SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy): The Sparse Categorical Crossentropy Loss Function. \n",
    "\n",
    "The arguments you will need:\n",
    "\n",
    "1. `from_logits`: This indicates if the values are raw values or normalized values (probabilities). Since the last layer of the model finishes with a LogSoftMax call, the results are **not** normalized - they do not lie between 0 and 1. \n",
    "2. `ignore_class`: This indicates which class should be ignored when computing the crossentropy. Remember that the class related to padding value is set to be 0.\n",
    "\n",
    "**Note**: You do not need to worry if the outputs are normalized or not in the accuracy case. Can you guess why? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6329015",
   "metadata": {},
   "source": [
    "<a name=\"ex04\"></a>\n",
    "### Exercise 4\n",
    "\n",
    "**Instructions**: You will use a `tf.keras.losses.SparseCategoricalCrossentropy` object to create a loss function that ignores the padded value related to the label. **Remember that for padding you are using the value** $-1$ **and not $0$, as opposed to the text padding!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1acb3d2",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: masked_loss\n",
    "def masked_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the masked sparse categorical cross-entropy loss.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (tensor): True labels.\n",
    "    y_pred (tensor): Predicted logits.\n",
    "    \n",
    "    Returns:\n",
    "    loss (tensor): Calculated loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True, ignore_class= -1)\n",
    "    loss = loss_fn(y_true,y_pred)\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return  loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb18b1a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1242604, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "true_labels = [0,1,2,0]\n",
    "predicted_logits = [[-2.3,-0.51,-1.20] , [-1.61,-0.36,-2.30], [-2.30, -0.69,-0.92], [-0.92,-0.92,-1.61]]\n",
    "print(masked_loss(true_labels, predicted_logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf9507",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "tf.Tensor(1.1242604, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7239dc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_masked_loss(masked_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c1afe",
   "metadata": {},
   "source": [
    "<a name=\"ex05\"></a>\n",
    "### Exercise 5\n",
    "\n",
    "**Instructions**: You will make a masked version of the accuracy function. You will need to perform an argmax to get the predicted label for each element in the batch. Remember to provide the appropriate axis in the argmax function. Furthermore, remember to use only tensorflow operations. Even though numpy has every function you will need, to pass it as a loss function and/or metric function, you must use tensorflow operations, due to internal optimizations that Tensorflow performs for reliable fitting. The following tensorflow functions are already loaded in memory, so you can directly call them.\n",
    "\n",
    "1. tf.equal, equivalent to np.equal\n",
    "2. tf.cast, equivalent to np.astype\n",
    "3. tf.reduce_sum, equiavalent to np.sum\n",
    "4. tf.math.argmax, equivalent to np.argmax\n",
    "5. You may need tf.float32 while casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f50fc477",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: masked_accuracy\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate masked accuracy for predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (tensor): True labels.\n",
    "    y_pred (tensor): Predicted logits.\n",
    "\n",
    "    Returns:\n",
    "    accuracy (tensor): Masked accuracy.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    mask = tf.math.not_equal(y_true, -1)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis = -1)\n",
    "    y_pred_class = tf.cast(y_pred_class, tf.float32)\n",
    "\n",
    "    matches_true_pred = tf.equal(y_true, y_pred_class)\n",
    "    matches_true_pred = tf.cast(matches_true_pred, tf.float32)\n",
    "\n",
    "    matches_true_pred *= mask\n",
    "    masked_acc = tf.reduce_sum(matches_true_pred) / tf.reduce_sum(mask)    \n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return masked_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f27aa010",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "true_labels = [0,1,2,0]\n",
    "predicted_logits = [[0.1,0.6,0.3] , [0.2,0.7,0.1], [0.1, 0.5,0.4], [0.4,0.4,0.2]]\n",
    "print(masked_accuracy(true_labels, predicted_logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcf95e",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "tf.Tensor(0.5, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72360a0a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_masked_accuracy(masked_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab287ac",
   "metadata": {},
   "source": [
    "Now you will create the model and get a summary of its parameters and layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "979d44f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 50)          1492400   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 50)          20200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 17)          867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,513,467\n",
      "Trainable params: 1,513,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = NER(len(tag_map), len(vocab))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77cb6a",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " embedding (Embedding)       (None, None, 50)          1492400   \n",
    "                                                                 \n",
    " lstm (LSTM)                 (None, None, 50)          20200     \n",
    "                                                                 \n",
    " dense (Dense)               (None, None, 17)          867       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1513467 (5.77 MB)\n",
    "Trainable params: 1513467 (5.77 MB)\n",
    "Non-trainable params: 0 (0.00 Byte)\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89d52a",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3 A note on padding\n",
    "\n",
    "You will check now how padding does not affect the model's output. Of course the output dimension will change. If ten zeros are added at the end of the tensor, then the resulting output dimension will have 10 more elements (more specifically, 10 more arrays of length 17 each). However, those are removed from any calculation further on, so it won't impact at all the model's performance and training. You will be using the function tf.expand_dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c943c7b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.expand_dims(np.array([545, 467, 896]), axis = 0) # Expanding dims is needed to pass it to the model, \n",
    "                                                        # since it expects batches and not single prediction arrays\n",
    "    \n",
    "x_padded = tf.expand_dims(np.array([545, 467, 896, 0, 0, 0]), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b37200a",
   "metadata": {},
   "source": [
    "Can you guess the final output prediction shape for each array defined above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8175d1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (1, 3, 17)\n",
      "x_padded shape: (1, 6, 17)\n"
     ]
    }
   ],
   "source": [
    "pred_x = model(x)\n",
    "pred_x_padded = model(x_padded)\n",
    "print(f'x shape: {pred_x.shape}\\nx_padded shape: {pred_x_padded.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca0596",
   "metadata": {},
   "source": [
    "If the last three elements of `pred_x_padded` are removed, both `pred_x` and `pred_x_padded[:3]` must have the same elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bd0ad65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pred_x, pred_x[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50f793",
   "metadata": {},
   "source": [
    "Great! Now one last check: let's see that both `pred_x` and `pred_x_padded` return the same loss and accuracy values. For that, you will need a `y_true` and `y_true_padded` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c97826b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_loss is the same: True\n",
      "masked_accuracy is the same: True\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.expand_dims([16, 6, 12], axis = 0)\n",
    "y_true_padded = tf.expand_dims([16,6,12,-1,-1,-1], axis = 0) # Remember you mapped the padded values to -1 in the labels\n",
    "print(f\"masked_loss is the same: {np.allclose(masked_loss(y_true,pred_x), masked_loss(y_true_padded,pred_x_padded))}\")\n",
    "print(f\"masked_accuracy is the same: {np.allclose(masked_accuracy(y_true,pred_x), masked_accuracy(y_true_padded,pred_x_padded))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a69bfc0",
   "metadata": {},
   "source": [
    "After this quick sanity check, you will now compile the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b77fc8",
   "metadata": {},
   "source": [
    "You will compile the model as follows:\n",
    "\n",
    "1. Use the Adam optimizer to compute the stochastic gradient descent, with learning rate 0.01\n",
    "2. Use the loss function `masked_loss` as loss function,\n",
    "3. As evaluation metrics, you will use both masked_loss and masked_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba387fb9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), \n",
    "              loss = masked_loss,\n",
    "               metrics = [masked_accuracy, masked_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71405c63",
   "metadata": {
    "colab_type": "text",
    "id": "-SdkBrFVnCuV"
   },
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### 4.4 - Training the Model\n",
    "\n",
    "You will now train the model. \n",
    "\n",
    "**Instructions:** \n",
    "\n",
    "- You will train it with `shuffle = True`, over 2 epochs and passing the validation dataset as `validation_data`.\n",
    "- You will run into an error if you just pass the datasets as they are right now, because they are not prepared in batches. You must use the method `.batch` that returns a dataset already divided in batches\n",
    "\n",
    "\n",
    "**NOTE**: The fitting takes about 1 minute to run. Only the first epoch is slow, the following ones are much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84b1b8be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "VU-j8hs-nCue",
    "outputId": "fbbbda7d-b6dd-42e4-a4c6-58c0a6e349b6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "525/525 [==============================] - 12s 21ms/step - loss: 0.0144 - masked_accuracy: 0.9767 - masked_loss: 0.0686 - val_loss: 0.0465 - val_masked_accuracy: 0.9553 - val_masked_loss: 0.1546\n",
      "Epoch 2/2\n",
      "525/525 [==============================] - 11s 20ms/step - loss: 0.0130 - masked_accuracy: 0.9789 - masked_loss: 0.0616 - val_loss: 0.0487 - val_masked_accuracy: 0.9550 - val_masked_loss: 0.1620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27dc2088a90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(33) ## Setting again a random seed to ensure reproducibility\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "model.fit(train_dataset.batch(BATCH_SIZE),\n",
    "          validation_data = val_dataset.batch(BATCH_SIZE),\n",
    "          shuffle=True,\n",
    "          epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270ad1f",
   "metadata": {
    "colab_type": "text",
    "id": "c4r-gXOZLr3j"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Compute Accuracy\n",
    "\n",
    "You will now evaluate on the test set. Previously, you have seen the accuracy on the training set and the validation (noted as eval) set. You will now evaluate on your test set. You already have a function to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78687bf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "yCWFwt3m1sgL",
    "outputId": "701d6b4d-b9b6-41f7-80b3-d0c043880704",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Convert the sentences into ids\n",
    "test_sentences_id = sentence_vectorizer(test_sentences)\n",
    "# Convert the labels into token ids\n",
    "test_labels_id = label_vectorizer(test_labels,tag_map)\n",
    "# Rename to prettify next function call\n",
    "y_true = test_labels_id \n",
    "y_pred = model.predict(test_sentences_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad366122",
   "metadata": {},
   "source": [
    "The next cell computes the accuracy for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eff0e106",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy in test set is: 0.9553\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model's accuracy in test set is: {masked_accuracy(y_true,y_pred).numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578a163",
   "metadata": {
    "colab_type": "text",
    "id": "EOeTPAx_Lr3t"
   },
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Testing with your Own Sentence\n",
    "\n",
    "In this section you will make a predictor function to predict the NER labels for any sentence. \n",
    "\n",
    "<a name=\"ex06\"></a>\n",
    "### Exercise 6\n",
    "\n",
    "**Instructions**: You will make a function `predict` that inputs one arbitrary sentence, a trained NER model, the sentence_vectorizer and the tag mapping and return a list of predicted NER labels. Remember that the sentences in pre-processing were already separated by token, so you do not need to worry about separating tokens such as commas or dots. You will just pass one sentence in the desired format, e.g., sentence = \"I like apples , oranges and grapes .\"\n",
    "\n",
    "To get a single prediction from a tensorflow model, you will need to make some changes in the input array, since tensorflow expects a batch of sentences. You can use the function `tf.expand_dims` to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14b7025a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "0K4SyB20cHRf",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "def predict(sentence, model, sentence_vectorizer, tag_map):\n",
    "    \"\"\"\n",
    "    Predict NER labels for a given sentence using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (str): Input sentence.\n",
    "    model (tf.keras.Model): Trained NER model.\n",
    "    sentence_vectorizer (tf.keras.layers.TextVectorization): Sentence vectorization layer.\n",
    "    tag_map (dict): Dictionary mapping tag IDs to labels.\n",
    "\n",
    "    Returns:\n",
    "    predictions (list): Predicted NER labels for the sentence.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    sentence_vectorized = sentence_vectorizer(sentence)\n",
    "    sentence_vectorized = tf.expand_dims(sentence_vectorized,axis = 0)\n",
    "    outputs = model.predict(sentence_vectorized)\n",
    "    outputs = np.argmax(outputs, axis = -1)\n",
    "    outputs = outputs[0]\n",
    "    labels = list(tag_map.keys())\n",
    "    pred = []\n",
    "    for tag_idx in outputs:\n",
    "        pred_label = labels[tag_idx]\n",
    "        pred.append(pred_label)\n",
    "   \n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2fe9e51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "w2_unittest.test_predict(predict, model, sentence_vectorizer, tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1be0189a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "deletable": false,
    "id": "vLZCHoiULr3u",
    "outputId": "fab815fd-0472-4eaf-968a-abff1f5cfff5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Peter B-per\n",
      "Parker I-per\n",
      "White B-org\n",
      "House I-org\n",
      "U.S B-org\n",
      "Sunday B-tim\n",
      "morning I-tim\n",
      "White B-org\n",
      "House I-org\n",
      "coronavirus B-org\n",
      "t I-org\n"
     ]
    }
   ],
   "source": [
    "# Try the output for the introduction example\n",
    "#sentence = \"Many French citizens are goin to visit Morocco for summer\"\n",
    "#sentence = \"Sharon Floyd flew to Miami last Friday\"\n",
    "\n",
    "# New york times news:\n",
    "sentence = \"Peter Parker , the White House director of trade and manufacturing policy of U.S , said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall , though he said it wouldn t necessarily come\"\n",
    "predictions = predict(sentence, model, sentence_vectorizer, tag_map)\n",
    "for x,y in zip(sentence.split(' '), predictions):\n",
    "    if y != 'O':\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb6c55",
   "metadata": {
    "colab_type": "text",
    "id": "NHYbSnYKnCu6"
   },
   "source": [
    "<span style=\"color:green\">Expected output:</span>\n",
    "\n",
    "```\n",
    "Peter B-per\n",
    "Parker I-per\n",
    "White B-org\n",
    "House I-org\n",
    "Sunday B-tim\n",
    "morning I-tim\n",
    "White B-org\n",
    "House I-org\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
